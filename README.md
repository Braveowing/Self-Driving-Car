基于KITTI数据集的无人驾驶感知与传感器融合实现
===
一、项目介绍
--
该项目基于KITTI数据集及相应的传感器标定参数，通过在行车过程中的传感器数据融合，实现无人驾驶汽车感知模块中的目标检测跟踪、TTC碰撞检测、车道线检测、运动目标轨迹预测功能；<br>

1.3D目标检测及跟踪：通过比较从传统机器学习SVM分类器，到当下无人车主流的深度学习模型YOLOv3，并验证在KITTI数据集上目标检测的表现<br>
2.TTC碰撞检测：应用BRISK/ORB/HARRIS等角点检测器和描述器，赋予目标检测框语义信息，实现前后帧的特征点跟踪，并通过KITTI数据集提供的传感器标定参数,将点云数据投射到2D图像，融合赋予特征点深度信息，利用CAM模型计算ROI区域碰撞时间TTC<br>
3.车道线检测：基于传统视觉处理算法，从颜色空间和梯度空间提取车道线特征<br><br>

二、项目目标
---
1.目标检测在KITTI数据集上mAP达到0.80以上<br>
2.TTC碰撞检测只针对车辆行驶方向上的ROI区域目标进行检测，单帧处理时间低于Lidar频率<br>
3.车道线检测能够适应白天阴影、弯道，并实现偏离中心检测<br><br>

三、最终效果图
---
![](https://github.com/Braveowing/Self-Driving-Car/blob/master/%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C%E5%9B%BE.png)<br><br>

四、逻辑框架图
---
![](https://github.com/Braveowing/Self-Driving-Car/blob/master/%E6%A1%86%E6%9E%B6%E7%BB%93%E6%9E%84.png)<br><br>
五、详细步骤
---
1. Camera内参标定<br>
2. 图像梯度空间特征提取<br>
3. 图像颜色空间特征提取<br>
4. 颜色空间&梯度空间结合提取特征<br>
5. 高斯滤波<br>
6. 角点检测器——Harris方法<br>
7. 角点检测器——FAST方法<br>
8. 目标检测描述器<br>
9. 描述子特征匹配<br>
10. 多种检测器/描述器及匹配算法组合比较<br>
11. 应用机器学习SVM分类器赋予图像语义信息<br>
12. 应用YOLOv3进行目标检测<br>
13. Camera-Lidar外参标定,点云与2D目标检测融合赋予深度信息<br>
14. 将目标检测框设置为ROI区域并对点云进行筛选<br>
15. 利用检测器和描述器将连续图像中ROI区域的keypoint匹配起来<br>
16. 进行TTC碰撞检测<br>
17. 车道线检测<br>
18. 将车道线检测与目标检测、TTC计算融合输出<br>
